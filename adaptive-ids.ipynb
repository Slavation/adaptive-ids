{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Torch Reptile Repository",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tda4Yz3rG2v7"
   },
   "source": [
    "# **Automated Machine Learning**\n",
    "\n",
    "---\n",
    "\n",
    "### **Torch Reptile - Parallel Metalearning**\n",
    "*Fall 2020 | Ruduan B.F. Plug*\n",
    "\n",
    "---\n",
    "\n",
    "<font size=\"1\">*Based on the Original Implementation by Alex Nichol & John Schulman [[1]](https://openai.com/blog/reptile/)*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzQ1T6HWX-S5"
   },
   "source": [
    "### Meta Libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YuqzrXatX_j1"
   },
   "source": [
    "# System Utility\n",
    "import sys\n",
    "\n",
    "# IPython Notebook Utilities\n",
    "from IPython.display import clear_output\n",
    "import tqdm.notebook as tqdm\n",
    "clear_output()\n",
    "\n",
    "print(sys.version)"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHOC5HMhP3sA"
   },
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MZ0KiCd6P34h",
    "ExecuteTime": {
     "end_time": "2025-10-30T16:21:17.024854Z",
     "start_time": "2025-10-30T16:21:17.015429Z"
    }
   },
   "source": [
    "# Data Processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Model Library\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parallel Compute\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Utility Libraries\n",
    "import random\n",
    "import math\n",
    "from time import time\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Device\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Torch Version\\t\", torch.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version\t 2.9.0+cpu\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahVLMwR55Rsz"
   },
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WM48Nv385dcL",
    "ExecuteTime": {
     "end_time": "2025-10-30T16:21:17.059155Z",
     "start_time": "2025-10-30T16:21:17.044015Z"
    }
   },
   "source": [
    "data_folder = \"data\"\n",
    "np.random.seed(int(time()))\n",
    "torch.manual_seed(int(time()))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2523e52c8b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFHo5IKxtA_L"
   },
   "source": [
    "### Reptile TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xti4UH95t4TI"
   },
   "source": [
    "#### Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2TEFbIOEtIR2",
    "ExecuteTime": {
     "end_time": "2025-10-30T16:21:17.085105Z",
     "start_time": "2025-10-30T16:21:17.068161Z"
    }
   },
   "source": [
    "class Reptile:\n",
    "\n",
    "  def __init__(self, model, log, params):\n",
    "\n",
    "    # Intialize Reptile Parameters\n",
    "    self.inner_step_size = params[0]\n",
    "    self.inner_batch_size = params[1]\n",
    "    self.outer_step_size = params[2]\n",
    "    self.outer_iterations = params[3]\n",
    "    self.meta_batch_size = params[4] \n",
    "    self.eval_iterations = params[5] \n",
    "    self.eval_batch_size = params[6]\n",
    "\n",
    "    # Initialize Torch Model and Tensorboard\n",
    "    self.model = model.to(device)\n",
    "    self.log = log\n",
    "\n",
    "  def reset(self):\n",
    "\n",
    "    # Reset Training Gradients\n",
    "    self.model.zero_grad()\n",
    "    self.current_loss = 0\n",
    "    self.current_batch = 0\n",
    "\n",
    "  def train(self, task):\n",
    "\n",
    "    # Train from Scratch\n",
    "    self.reset()\n",
    "\n",
    "    # Outer Training Loop\n",
    "    for outer_iteration in tqdm.tqdm(range(self.outer_iterations)):\n",
    "\n",
    "      # Track Current Weights\n",
    "      current_weights = deepcopy(self.model.state_dict())\n",
    "\n",
    "      # Inner Training Loop\n",
    "      for inner_iteration in range(self.inner_batch_size):\n",
    "\n",
    "          # Sample a new Subtask\n",
    "          x_task, y_task = sample(task)\n",
    "\n",
    "          batch_loss = self.loss(x_task, y_task)\n",
    "          batch_loss.backward()\n",
    "\n",
    "          # Update Model Parameters\n",
    "          for theta in self.model.parameters():\n",
    "\n",
    "            # Get Parameter Gradient\n",
    "            grad = theta.grad.data\n",
    "\n",
    "            # Update Model Parameter\n",
    "            theta.data -= self.inner_step_size * grad\n",
    "\n",
    "          # Update Model Loss from Torch Model Tensor\n",
    "          loss_tensor = batch_loss.cpu()\n",
    "          self.current_loss += loss_tensor.item()\n",
    "          self.current_batch += 1\n",
    "\n",
    "      # Linear Cooling Schedule\n",
    "      alpha = self.outer_step_size * (1 - outer_iteration / self.outer_iterations)\n",
    "\n",
    "      # Get Current Candidate Weights\n",
    "      candidate_weights = self.model.state_dict()\n",
    "\n",
    "      # Transfer Candidate Weights to Model State Checkpoint\n",
    "      state_dict = {candidate: (current_weights[candidate] + alpha * \n",
    "                               (candidate_weights[candidate] - current_weights[candidate])) \n",
    "                                for candidate in candidate_weights}\n",
    "      self.model.load_state_dict(state_dict)\n",
    "      \n",
    "      # Log new Training Loss\n",
    "      self.log.add_scalar('Model Estimate/Loss',\n",
    "                           self.current_loss / self.current_batch,\n",
    "                           outer_iteration)\n",
    "\n",
    "  def loss(self, x, y):\n",
    "\n",
    "    # Reset Torch Gradient\n",
    "    self.model.zero_grad()\n",
    "\n",
    "    # Calculate Torch Tensors\n",
    "    x = torch.tensor(x, device = device, dtype = torch.float32)\n",
    "    y = torch.tensor(y, device = device, dtype = torch.float32)\n",
    "\n",
    "    # Estimate over Sample\n",
    "    yhat = self.model(x)\n",
    "\n",
    "    # Regression Loss over Estimate\n",
    "    loss = nn.MSELoss()\n",
    "    output = loss(yhat, y)\n",
    "\n",
    "    return output\n",
    "\n",
    "  def predict(self, x):\n",
    "\n",
    "    # Estimate using Torch Model\n",
    "    t = torch.tensor(x, device = device, dtype = torch.float32)\n",
    "    t = self.model(t)\n",
    "\n",
    "    # Bring Torch Tensor from GPU to System Host Memory\n",
    "    t = t.cpu()\n",
    "\n",
    "    # Return Estimate as Numpy Float\n",
    "    y = t.data.numpy()\n",
    "\n",
    "    return y\n",
    "\n",
    "  def eval(self, X_eval, y_eval, gradient_steps=5):\n",
    "\n",
    "    # Sample Points from Task Sample Space\n",
    "    x = torch.tensor(X_eval, device=device, dtype=torch.float32)\n",
    "    y = torch.tensor(np.array(y_eval), device=device, dtype=torch.float32)\n",
    "\n",
    "    # Store Meta-Initialization Weights\n",
    "    meta_weights = deepcopy(self.model.state_dict())\n",
    "\n",
    "    # Get Estimate Loss over Meta-Initialization\n",
    "    loss_t = self.loss(X_eval,y_eval).cpu()\n",
    "    meta_loss = loss_t.item()\n",
    "\n",
    "    # Calculcate Estimate over Gradient Steps\n",
    "    for step in range(gradient_steps):\n",
    "\n",
    "      # Calculate Evaluation Loss and Backpropagate\n",
    "      eval_loss = self.loss(X_eval,y_eval)\n",
    "      eval_loss.backward()\n",
    "\n",
    "      # Update Model Estimate Parameters\n",
    "      for theta in self.model.parameters():\n",
    "\n",
    "        # Get Parameter Gradient\n",
    "        grad = theta.grad.data\n",
    "\n",
    "        # Update Model Parameter\n",
    "        theta.data -= self.inner_step_size * grad\n",
    "\n",
    "    # Get Estimate Loss over Evaluation\n",
    "    loss_t = self.loss(x,y).cpu()\n",
    "    estimate_loss = loss_t.item()\n",
    "    evaluation_loss = abs(meta_loss - estimate_loss)/len(X_eval)\n",
    "    \n",
    "    # Restore Meta-Initialization Weights\n",
    "    self.model.load_state_dict(meta_weights)\n",
    "\n",
    "    preds = self.predict(X_eval)\n",
    "    preds = (preds > 0.5).astype(float)\n",
    "    accuracy = np.mean(preds.squeeze() == np.array(y_eval).astype(float))\n",
    "\n",
    "    return accuracy, evaluation_loss"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARn0cnaCT4I6"
   },
   "source": [
    "#### PyTorch Module"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fzQaKtGLT4YP",
    "ExecuteTime": {
     "end_time": "2025-10-30T16:21:17.097400Z",
     "start_time": "2025-10-30T16:21:17.091112Z"
    }
   },
   "source": [
    "class TorchModule(nn.Module):\n",
    "\n",
    "  def __init__(self, in_features, n):\n",
    "\n",
    "    # Initialize PyTorch Base Module\n",
    "    super(TorchModule, self).__init__()\n",
    "\n",
    "    # Define Multi-Layer Perceptron\n",
    "    self.input = nn.Linear(in_features,n)\n",
    "    self.hidden_in = nn.Linear(n,n)\n",
    "    self.hidden_out = nn.Linear(n,n)\n",
    "    self.output = nn.Linear(n,1)\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    # PyTorch Feed Forward Subroutine\n",
    "    x = torch.tanh(self.input(x))\n",
    "    x = torch.tanh(self.hidden_in(x))\n",
    "    x = torch.tanh(self.hidden_out(x))\n",
    "    y = self.output(x)\n",
    "\n",
    "    return y"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cdfjr05yiF_T"
   },
   "source": [
    "### Learning Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAf2MjOoUKL8"
   },
   "source": [
    "#### Task Sampler"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OhxxbAe1ULpM",
    "ExecuteTime": {
     "end_time": "2025-10-30T16:21:17.109539Z",
     "start_time": "2025-10-30T16:21:17.105407Z"
    }
   },
   "source": [
    "def sample(task):\n",
    "\n",
    "  normal_idx = np.where(y_train == 0)[0]\n",
    "  attack_idx = np.where(y_train == 1)[0]\n",
    "  half = 64\n",
    "\n",
    "  idx = np.concatenate([\n",
    "      np.random.choice(normal_idx, half, replace=False),\n",
    "      np.random.choice(attack_idx, half, replace=False)\n",
    "  ])\n",
    "\n",
    "  np.random.shuffle(idx)\n",
    "  y_batch = y_train.values[idx] if hasattr(y_train, \"values\") else y_train[idx]\n",
    "  y_batch = y_batch.reshape(-1, 1)\n",
    "\n",
    "  return X_train[idx], y_batch"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9W4j4rW0yuS"
   },
   "source": "## Dataset"
  },
  {
   "metadata": {
    "id": "OhxxbAe1ULpM",
    "ExecuteTime": {
     "end_time": "2025-10-30T16:21:43.807808Z",
     "start_time": "2025-10-30T16:21:17.118555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the preprocessed dataset\n",
    "df = pd.read_csv(\"dataset/preprocessed_DNN.csv\")\n",
    "print(\"Loaded preprocessed dataset:\", df.shape)\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.drop(columns=[\"Attack_label\", \"Attack_type\"], errors=\"ignore\")\n",
    "y = df[\"Attack_label\"].astype(int)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded preprocessed dataset: (1909671, 97)\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Experiments"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RDm4ny3Qt0em",
    "ExecuteTime": {
     "end_time": "2025-10-30T16:22:52.195426Z",
     "start_time": "2025-10-30T16:21:43.863389Z"
    }
   },
   "source": [
    "# Define Experiment Parameters\n",
    "inner_step_size = 0.02\n",
    "inner_batch_size = 16\n",
    "\n",
    "outer_step_size = 0.1\n",
    "outer_iterations = 100\n",
    "meta_batch_size = 32\n",
    "\n",
    "eval_iterations = 32\n",
    "eval_batch_size = 10\n",
    "eval_range = range(1,11)\n",
    "\n",
    "model_size = 32\n",
    "sample_radius = 20\n",
    "sample_count = 100\n",
    "\n",
    "params = [inner_step_size, inner_batch_size,\n",
    "          outer_step_size, outer_iterations, meta_batch_size,\n",
    "          eval_iterations, eval_batch_size]\n",
    "\n",
    "# Define Experiment Task and Model\n",
    "log = SummaryWriter(data_folder)\n",
    "model = Reptile(TorchModule(X_train.shape[1], model_size), log, params)\n",
    "\n",
    "# Train Model\n",
    "model.train(task=None)\n",
    "\n",
    "with torch.no_grad():\n",
    "  preds = model.predict(X_test)\n",
    "  preds = (preds > 0.5).astype(float)\n",
    "  acc = np.mean(preds.squeeze() == y_test.values.astype(float))\n",
    "  print(f\"Test Accuracy: {acc:.4f}\")\n",
    "  log.add_scalar('Model Estimate/Test_Accuracy', acc)\n",
    "\n",
    "log.close()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c8e3e9bdbcb4c48aaebf19ee5d8f261"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9974\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jiPJ9EM9278"
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SixEsDGC0y7s",
    "ExecuteTime": {
     "end_time": "2025-10-30T16:23:05.348322Z",
     "start_time": "2025-10-30T16:22:52.313109Z"
    }
   },
   "source": [
    "%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir data"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-75a0825225233b3c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-75a0825225233b3c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "a4c7395a34effe1c727fabf3e46045d8"
     }
    }
   ],
   "execution_count": 25
  }
 ]
}
