{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Torch Reptile Repository",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tda4Yz3rG2v7"
   },
   "source": [
    "# **Automated Machine Learning**\n",
    "\n",
    "---\n",
    "\n",
    "### **Reptile-Based Few-Shot Intrusion Detection System**\n",
    "*2026 | Vladislav Zagidulin*\n",
    "\n",
    "---\n",
    "\n",
    "<font size=\"1\"> Based on the Reptile meta-learning algorithm proposed by Alex Nichol and John Schulman [[1]](https://openai.com/research/reptile) and draws from the Torch Reptile implementation by Ruduan B. F. Plug [[2]](https://github.com/dualslash/reptile-torch)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHOC5HMhP3sA"
   },
   "source": "### Meta Libraries"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# System Utility\n",
    "import sys\n",
    "\n",
    "# IPython Notebook Utilities\n",
    "from IPython.display import clear_output\n",
    "import tqdm.notebook as tqdm\n",
    "clear_output()\n",
    "\n",
    "print(sys.version)"
   ],
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]\n"
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Packages"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MZ0KiCd6P34h",
    "ExecuteTime": {
     "end_time": "2026-01-15T15:29:28.550412Z",
     "start_time": "2026-01-15T15:29:28.544051Z"
    }
   },
   "source": [
    "# Data Processing\n",
    "import numpy as np\n",
    "\n",
    "# Parallel Compute\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Utility Libraries\n",
    "from time import time\n",
    "from copy import deepcopy\n",
    "\n",
    "# Initialize Device\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Torch Version\\t\", torch.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version\t 2.9.0+cpu\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahVLMwR55Rsz"
   },
   "source": "### Environment Configuration"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WM48Nv385dcL",
    "ExecuteTime": {
     "end_time": "2026-01-15T15:29:28.565638Z",
     "start_time": "2026-01-15T15:29:28.550412Z"
    }
   },
   "source": [
    "data_folder = \"data\"\r\n",
    "np.random.seed(int(time()))\r\n",
    "torch.manual_seed(int(time()))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2a6eec11c90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFHo5IKxtA_L"
   },
   "source": "### Meta-Learning Framework"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xti4UH95t4TI"
   },
   "source": "#### Reptile Class Definition"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2TEFbIOEtIR2",
    "ExecuteTime": {
     "end_time": "2026-01-15T15:29:28.589706Z",
     "start_time": "2026-01-15T15:29:28.574249Z"
    }
   },
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "class Reptile:\n",
    "\n",
    "  def __init__(self, model, log, params):\n",
    "\n",
    "    # Intialize Reptile Parameters\n",
    "    self.inner_step_size = params[0]\n",
    "    self.inner_batch_size = params[1]\n",
    "    self.outer_step_size = params[2]\n",
    "    self.outer_iterations = params[3]\n",
    "    self.meta_batch_size = params[4]\n",
    "\n",
    "    # Initialize Torch Model and Tensorboard\n",
    "    self.model = model.to(device)\n",
    "    self.log = log\n",
    "\n",
    "  def reset(self):\n",
    "\n",
    "    # Reset Training Gradients\n",
    "    self.model.zero_grad()\n",
    "\n",
    "  def train(self, x, y):\n",
    "\n",
    "    # Train from Scratch\n",
    "    self.reset()\n",
    "    self.model.train()\n",
    "\n",
    "    # Outer Training Loop\n",
    "    for outer_iteration in tqdm.tqdm(range(self.outer_iterations)):\n",
    "\n",
    "      # Track Current Weights\n",
    "      current_weights = deepcopy(self.model.state_dict())\n",
    "\n",
    "      # Sample a new Subtask\n",
    "      (x_support, y_support), (x_query, y_query) = sample_task(\n",
    "         x, y,\n",
    "         allowed_classes=train_classes,\n",
    "         n_way=N_WAY,\n",
    "         k_shot=K_SHOT,\n",
    "         query_size=QUERY_SIZE\n",
    "      )\n",
    "\n",
    "      x_support = x_support.to(device)\n",
    "      y_support = y_support.to(device)\n",
    "      x_query   = x_query.to(device)\n",
    "      y_query   = y_query.to(device)\n",
    "\n",
    "      # Inner Training Loop\n",
    "      for inner_iteration in range(self.inner_batch_size):\n",
    "\n",
    "        perm = torch.randperm(x_support.shape[0])\n",
    "\n",
    "        # Process Meta Learning Batches\n",
    "        for batch in range(0, x_support.shape[0], self.meta_batch_size):\n",
    "\n",
    "          # Get Permuted Batch from Sample\n",
    "          idx = perm[batch:batch + self.meta_batch_size]\n",
    "\n",
    "          # Calculate Batch Loss\n",
    "          self.model.zero_grad()\n",
    "          batch_loss = self.loss(x_support[idx], y_support[idx])\n",
    "          batch_loss.backward()\n",
    "\n",
    "          # Update Model Parameters\n",
    "          for theta in self.model.parameters():\n",
    "\n",
    "            if theta.grad is not None:\n",
    "                theta.data -= self.inner_step_size * theta.grad.data\n",
    "\n",
    "      # Compute meta-loss\n",
    "      with torch.no_grad():\n",
    "         query_loss = self.loss(x_query, y_query)\n",
    "\n",
    "      # Linear Cooling Schedule\n",
    "      alpha = self.outer_step_size * (1 - outer_iteration / self.outer_iterations)\n",
    "\n",
    "      # Get Current Candidate Weights\n",
    "      candidate_weights = self.model.state_dict()\n",
    "\n",
    "      # Transfer Candidate Weights to Model State Checkpoint\n",
    "      state_dict = {candidate: (current_weights[candidate] + alpha * \n",
    "                               (candidate_weights[candidate] - current_weights[candidate])) \n",
    "                                for candidate in candidate_weights}\n",
    "      self.model.load_state_dict(state_dict)\n",
    "      \n",
    "      # Log new Training Loss\n",
    "      self.log.add_scalar('ModelEstimate/Loss', query_loss.item(), outer_iteration)\n",
    "\n",
    "      # Log evaluation accuracy and precision\n",
    "      if outer_iteration % 50 == 0:\n",
    "        mean_acc, _, mean_prec, _, mean_rec, _, mean_f1, _ = evaluate_episodes(self, x, y, allowed_classes=train_classes, n_episodes=50)\n",
    "\n",
    "        self.log.add_scalar('Episode/MeanAccuracy', mean_acc, outer_iteration)\n",
    "        self.log.add_scalar('Episode/MeanPrecision', mean_prec, outer_iteration)\n",
    "        self.log.add_scalar('Episode/MeanRecall', mean_rec, outer_iteration)\n",
    "        self.log.add_scalar('Episode/MeanF1', mean_f1, outer_iteration)\n",
    "\n",
    "  def loss(self, x, y):\n",
    "    # Compute model output\n",
    "    logits = self.model(x)\n",
    "\n",
    "    # Cross Entropy Loss\n",
    "    calculatedLoss = nn.CrossEntropyLoss()\n",
    "    output = calculatedLoss(logits, y)\n",
    "\n",
    "    return output\n",
    "\n",
    "  def predict(self, x):\n",
    "\n",
    "    # Estimate using Torch Model\n",
    "    t = torch.tensor(x, device = device, dtype = torch.float32)\n",
    "    t = self.model(t)\n",
    "\n",
    "    prediction = torch.argmax(t, dim=1)\n",
    "\n",
    "    return prediction.cpu().numpy()\n",
    "\n",
    "  def eval(self, x, y, allowed_classes, gradient_steps=5):\n",
    "      self.model.eval()\n",
    "\n",
    "      # Sample a task\n",
    "      (x_support, y_support), (x_query, y_query) = sample_task(\n",
    "         x, y,\n",
    "         allowed_classes=allowed_classes,\n",
    "         n_way=N_WAY,\n",
    "         k_shot=K_SHOT,\n",
    "         query_size=QUERY_SIZE\n",
    "      )\n",
    "\n",
    "      x_support = x_support.to(device)\n",
    "      y_support = y_support.to(device)\n",
    "      x_query   = x_query.to(device)\n",
    "      y_query   = y_query.to(device)\n",
    "\n",
    "      # Store Meta-Initialization Weights\n",
    "      meta_weights = deepcopy(self.model.state_dict())\n",
    "\n",
    "      # Calculate Estimate over Gradient Steps\n",
    "      for step in range(gradient_steps):\n",
    "\n",
    "        # Calculate Evaluation Loss and Backpropagate\n",
    "        self.model.zero_grad()\n",
    "        loss = self.loss(x_support, y_support)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update Model Estimate Parameters\n",
    "        for theta in self.model.parameters():\n",
    "\n",
    "            if theta.grad is not None:\n",
    "                theta.data -= self.inner_step_size * theta.grad.data\n",
    "\n",
    "      # Get Estimate Loss over Evaluation\n",
    "      with torch.no_grad():\n",
    "          logits = self.model(x_query)\n",
    "          predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "      # Accuracy\n",
    "      accuracy = (predictions == y_query).float().mean().item()\n",
    "\n",
    "      # Precision\n",
    "      precision = precision_score(\n",
    "          y_query.cpu().numpy(),\n",
    "          predictions.cpu().numpy(),\n",
    "          average='macro',\n",
    "          zero_division=0\n",
    "      )\n",
    "\n",
    "      # Recall\n",
    "      recall = recall_score(\n",
    "          y_query.cpu().numpy(),\n",
    "          predictions.cpu().numpy(),\n",
    "          average='macro',\n",
    "          zero_division=0\n",
    "      )\n",
    "\n",
    "      # F1 Score\n",
    "      f1 = f1_score(\n",
    "          y_query.cpu().numpy(),\n",
    "          predictions.cpu().numpy(),\n",
    "          average='macro',\n",
    "          zero_division=0\n",
    "      )\n",
    "\n",
    "      # Restore Meta-Initialization Weights\n",
    "      self.model.load_state_dict(meta_weights)\n",
    "      self.model.train()\n",
    "\n",
    "      return accuracy, precision, recall, f1\n",
    "\n",
    "def evaluate_episodes(model, x, y, allowed_classes, n_episodes, gradient_steps=5):\n",
    "    accs, precs, recs, f1s = [], [], [], []\n",
    "    for _ in range(n_episodes):\n",
    "        acc, prec, rec, f1 = model.eval(x, y, allowed_classes=allowed_classes, gradient_steps=gradient_steps)\n",
    "        accs.append(acc)\n",
    "        precs.append(prec)\n",
    "        recs.append(rec)\n",
    "        f1s.append(f1)\n",
    "    return (\n",
    "        np.mean(accs), np.std(accs),\n",
    "        np.mean(precs), np.std(precs),\n",
    "        np.mean(recs), np.std(recs),\n",
    "        np.mean(f1s), np.std(f1s)\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Task Sampler"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T15:29:28.601971Z",
     "start_time": "2026-01-15T15:29:28.596761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "N_WAY = 3       # number of classes per episode\n",
    "K_SHOT = 5      # support samples per class\n",
    "QUERY_SIZE = 15  # query samples per class\n",
    "HIDDEN_DIM = 128\n",
    "\n",
    "def sample_task(x, y, allowed_classes, n_way=N_WAY, k_shot=K_SHOT, query_size=QUERY_SIZE):\n",
    "    # Work with numpy view of labels\n",
    "    y_np = y.cpu().numpy()\n",
    "    needed = k_shot + query_size\n",
    "\n",
    "    # Only classes that are allowed and have enough samples\n",
    "    valid_classes = [\n",
    "        c for c in allowed_classes\n",
    "        if np.sum(y_np == c) >= needed\n",
    "    ]\n",
    "\n",
    "    if len(valid_classes) < n_way:\n",
    "        raise ValueError(\"Not enough valid classes for this N-way task\")\n",
    "\n",
    "    # Randomly choose n_way classes from the valid ones\n",
    "    classes = np.random.choice(valid_classes, n_way, replace=False)\n",
    "\n",
    "    support_x = []\n",
    "    support_y = []\n",
    "    query_x = []\n",
    "    query_y = []\n",
    "\n",
    "    # Map global label -> episodic label 0..n_way-1\n",
    "    class_mapping = {int(c): i for i, c in enumerate(classes)}\n",
    "\n",
    "    for c in classes:\n",
    "        idx = np.where(y_np == c)[0]             # indices of this class\n",
    "        chosen = np.random.choice(idx, needed, replace=False)\n",
    "\n",
    "        support = chosen[:k_shot]\n",
    "        query = chosen[k_shot:]\n",
    "\n",
    "        support_x.append(x[support])\n",
    "        query_x.append(x[query])\n",
    "\n",
    "        # Episodic labels 0..n_way-1\n",
    "        episodic_label = class_mapping[int(c)]\n",
    "        support_y.append(torch.full((len(support),), episodic_label, dtype=torch.long))\n",
    "        query_y.append(torch.full((len(query),), episodic_label, dtype=torch.long))\n",
    "\n",
    "    x_support = torch.cat(support_x, dim=0)\n",
    "    y_support = torch.cat(support_y, dim=0)\n",
    "    x_query = torch.cat(query_x, dim=0)\n",
    "    y_query = torch.cat(query_y, dim=0)\n",
    "\n",
    "    return (x_support, y_support), (x_query, y_query)\n"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "id": "fzQaKtGLT4YP",
    "ExecuteTime": {
     "end_time": "2025-12-03T18:15:54.904996Z",
     "start_time": "2025-12-03T18:15:54.898302Z"
    }
   },
   "cell_type": "markdown",
   "source": "#### PyTorch Module\n"
  },
  {
   "metadata": {
    "id": "fzQaKtGLT4YP",
    "ExecuteTime": {
     "end_time": "2026-01-15T15:29:28.611011Z",
     "start_time": "2026-01-15T15:29:28.607215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TorchModule(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=HIDDEN_DIM, num_classes=N_WAY):\n",
    "        super(TorchModule, self).__init__()\n",
    "\n",
    "        self.input = nn.Linear(input_dim, hidden_dim)\n",
    "        self.hidden = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input(x))\n",
    "        x = torch.relu(self.hidden(x))\n",
    "        return self.output(x)\n"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Preprocessing"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T15:29:30.715737Z",
     "start_time": "2026-01-15T15:29:28.616019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"dataset/ML-EdgeIIoT-dataset-test.csv\", low_memory=False)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "drop_cols = [\n",
    "    \"frame.time\",\n",
    "    \"ip.src_host\",\n",
    "    \"ip.dst_host\",\n",
    "    \"arp.src.proto_ipv4\",\n",
    "    \"arp.dst.proto_ipv4\",\n",
    "    \"http.file_data\",\n",
    "    \"http.request.full_uri\",\n",
    "    \"http.request.uri.query\",\n",
    "    \"icmp.transmit_timestamp\",\n",
    "    \"tcp.options\",\n",
    "    \"tcp.payload\",\n",
    "    \"tcp.srcport\",\n",
    "    \"tcp.dstport\",\n",
    "    \"udp.port\",\n",
    "    \"mqtt.msg\",\n",
    "]\n",
    "\n",
    "df.drop(columns=drop_cols, inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Clean values\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(axis=0, how='any', inplace=True)\n",
    "df.drop_duplicates(subset=None, keep=\"first\", inplace=True)\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_cols = [\n",
    "    'http.request.method',\n",
    "    'http.referer',\n",
    "    'http.request.version',\n",
    "    'dns.qry.name.len',\n",
    "    'mqtt.conack.flags',\n",
    "    'mqtt.protoname',\n",
    "    'mqtt.topic',\n",
    "]\n",
    "\n",
    "df = pd.get_dummies(df, columns=categorical_cols)\n",
    "\n",
    "# Separate features and labels\n",
    "x = df.drop(columns=[\"Attack_type\", \"Attack_label\"])\n",
    "\n",
    "# Encode Attack_type labels\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(df[\"Attack_type\"])\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "# Convert to tensors\n",
    "x = torch.tensor(x, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "print(\"Dataset loaded:\", x.shape, y.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: torch.Size([152196, 74]) torch.Size([152196])\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9W4j4rW0yuS"
   },
   "source": "#### Split Data"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T15:29:30.912850Z",
     "start_time": "2026-01-15T15:29:30.739464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get all unique class labels\n",
    "all_classes = np.unique(y.numpy())\n",
    "\n",
    "# Fix seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Choose 80% classes for meta-training\n",
    "num_meta_train = int(0.8 * len(all_classes))\n",
    "train_classes = np.random.choice(all_classes, size=num_meta_train, replace=False)\n",
    "\n",
    "# Remaining classes are test\n",
    "test_classes = np.array([c for c in all_classes if c not in train_classes])\n",
    "\n",
    "print(\"Train Classes:\", train_classes)\n",
    "print(\"Test Classes:\", test_classes)\n",
    "\n",
    "# Create dataset masks\n",
    "train_mask = np.isin(y.numpy(), train_classes)\n",
    "test_mask  = np.isin(y.numpy(), test_classes)\n",
    "\n",
    "# Filter datasets\n",
    "x_train = x[train_mask]\n",
    "y_train = y[train_mask]\n",
    "\n",
    "x_test  = x[test_mask]\n",
    "y_test  = y[test_mask]\n",
    "\n",
    "print(\"Train set:\", x_train.shape, y_train.shape)\n",
    "print(\"Test set:\",  x_test.shape,  y_test.shape)\n",
    "\n",
    "# Increase sample of minority classes using SMOTE\n",
    "# smote = SMOTE(k_neighbors=5, random_state=42)\n",
    "#\n",
    "# x_train_np = x_train.numpy()\n",
    "# y_train_np = y_train.numpy()\n",
    "# x_train_res, y_train_res = smote.fit_resample(x_train_np, y_train_np)\n",
    "\n",
    "# print(\"Train set:\", x_train.shape, y_train.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Classes: [ 9 11  0 13  5  8  2  1 14  4  7 10]\n",
      "Test Classes: [ 3  6 12]\n",
      "Train set: torch.Size([131377, 74]) torch.Size([131377])\n",
      "Test set: torch.Size([20819, 74]) torch.Size([20819])\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Experiments"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jiPJ9EM9278"
   },
   "source": [
    "### Results"
   ]
  },
  {
   "metadata": {
    "id": "RDm4ny3Qt0em",
    "ExecuteTime": {
     "end_time": "2026-01-15T15:31:05.685947Z",
     "start_time": "2026-01-15T15:29:30.920301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define Experiment Parameters\n",
    "inner_step_size = 0.02\n",
    "inner_batch_size = 15\n",
    "\n",
    "outer_step_size = 0.1\n",
    "outer_iterations = 3000\n",
    "meta_batch_size = 15\n",
    "\n",
    "params = [inner_step_size, inner_batch_size,\n",
    "          outer_step_size, outer_iterations, meta_batch_size]\n",
    "\n",
    "# Build Model\n",
    "input_dim = x.shape[1]\n",
    "log = SummaryWriter(data_folder)\n",
    "reptile_model = Reptile(TorchModule(input_dim, hidden_dim=HIDDEN_DIM, num_classes=N_WAY), log, params)\n",
    "\n",
    "# Train Model\n",
    "reptile_model.train(x_train, y_train)\n",
    "\n",
    "log.close()\n",
    "\n",
    "# Zero-day evaluation on unseen test classes\n",
    "mean_acc, std_acc, mean_prec, std_prec, mean_rec, std_rec, mean_f1, std_f1 = evaluate_episodes(\n",
    "    reptile_model,\n",
    "    x_test, y_test,\n",
    "    allowed_classes=test_classes,\n",
    "    n_episodes=200,\n",
    ")\n",
    "\n",
    "ci_acc  = 1.96 * std_acc  / np.sqrt(200)\n",
    "ci_prec = 1.96 * std_prec / np.sqrt(200)\n",
    "ci_rec = 1.96 * std_rec / np.sqrt(200)\n",
    "ci_f1 = 1.96 * std_f1 / np.sqrt(200)\n",
    "\n",
    "print(f\"Zero-Day {N_WAY}-Way Accuracy : {mean_acc:.4f} ± {ci_acc:.4f}\")\n",
    "print(f\"Zero-Day {N_WAY}-Way Precision: {mean_prec:.4f} ± {ci_prec:.4f}\")\n",
    "print(f\"Zero-Day {N_WAY}-Way Recall: {mean_rec:.4f} ± {ci_rec:.4f}\")\n",
    "print(f\"Zero-Day {N_WAY}-Way F1-Score: {mean_f1:.4f} ± {ci_f1:.4f}\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6cee6dbf482f4f12a0022f92fb88dcb8"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-Day 3-Way Accuracy : 0.9762 ± 0.0058\n",
      "Zero-Day 3-Way Precision: 0.9806 ± 0.0043\n",
      "Zero-Day 3-Way Recall: 0.9762 ± 0.0058\n",
      "Zero-Day 3-Way F1-Score: 0.9756 ± 0.0061\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "id": "SixEsDGC0y7s",
    "ExecuteTime": {
     "end_time": "2026-01-15T15:31:05.753779Z",
     "start_time": "2026-01-15T15:31:05.736440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir data"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 20484), started 0:34:00 ago. (Use '!kill 20484' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "5b134dfa5d6f791ac08e94f2b684f962"
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6aea41abc48767d5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6aea41abc48767d5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 39
  }
 ]
}
