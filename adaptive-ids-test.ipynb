{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Torch Reptile Repository",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tda4Yz3rG2v7"
   },
   "source": [
    "# **Automated Machine Learning**\n",
    "\n",
    "---\n",
    "\n",
    "### **Torch Reptile - Parallel Metalearning**\n",
    "*Fall 2020 | Ruduan B.F. Plug*\n",
    "\n",
    "---\n",
    "\n",
    "<font size=\"1\">*Based on the Original Implementation by Alex Nichol & John Schulman [[1]](https://openai.com/blog/reptile/)*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzQ1T6HWX-S5"
   },
   "source": [
    "### Meta Libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YuqzrXatX_j1"
   },
   "source": [
    "# System Utility\n",
    "import sys\n",
    "\n",
    "# IPython Notebook Utilities\n",
    "from IPython.display import clear_output\n",
    "import tqdm.notebook as tqdm\n",
    "clear_output()\n",
    "\n",
    "print(sys.version)"
   ],
   "execution_count": 204,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHOC5HMhP3sA"
   },
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MZ0KiCd6P34h",
    "ExecuteTime": {
     "end_time": "2025-11-18T19:27:20.835195Z",
     "start_time": "2025-11-18T19:27:20.830193Z"
    }
   },
   "source": [
    "# Data Processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Model Library\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parallel Compute\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Utility Libraries\n",
    "import random\n",
    "import math\n",
    "from time import time\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Device\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Torch Version\\t\", torch.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version\t 2.9.0+cpu\n"
     ]
    }
   ],
   "execution_count": 205
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahVLMwR55Rsz"
   },
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WM48Nv385dcL",
    "ExecuteTime": {
     "end_time": "2025-11-18T19:27:20.853077Z",
     "start_time": "2025-11-18T19:27:20.844716Z"
    }
   },
   "source": [
    "data_folder = \"data\"\r\n",
    "np.random.seed(int(time()))\r\n",
    "torch.manual_seed(int(time()))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x29d3307c910>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 206
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFHo5IKxtA_L"
   },
   "source": "### Reptile TensorFlow"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xti4UH95t4TI"
   },
   "source": [
    "#### Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2TEFbIOEtIR2",
    "ExecuteTime": {
     "end_time": "2025-11-18T19:27:20.873364Z",
     "start_time": "2025-11-18T19:27:20.859092Z"
    }
   },
   "source": [
    "class Reptile:\n",
    "\n",
    "  def __init__(self, model, log, params):\n",
    "\n",
    "    # Intialize Reptile Parameters\n",
    "    self.inner_step_size = params[0]\n",
    "    self.inner_batch_size = params[1]\n",
    "    self.outer_step_size = params[2]\n",
    "    self.outer_iterations = params[3]\n",
    "    self.meta_batch_size = params[4]\n",
    "\n",
    "    # Initialize Torch Model and Tensorboard\n",
    "    self.model = model.to(device)\n",
    "    self.log = log\n",
    "\n",
    "  def reset(self):\n",
    "\n",
    "    # Reset Training Gradients\n",
    "    self.model.zero_grad()\n",
    "\n",
    "  def train(self, X, y):\n",
    "\n",
    "    # Train from Scratch\n",
    "    self.reset()\n",
    "    self.model.train()\n",
    "\n",
    "    # Outer Training Loop\n",
    "    for outer_iteration in tqdm.tqdm(range(self.outer_iterations)):\n",
    "\n",
    "      # Track Current Weights\n",
    "      current_weights = deepcopy(self.model.state_dict())\n",
    "\n",
    "      # Sample a new Subtask\n",
    "      (X_support, y_support), (X_query, y_query) = sample_task(\n",
    "         X, y,\n",
    "         allowed_classes=train_classes,\n",
    "         n_way=N_WAY,\n",
    "         k_shot=K_SHOT,\n",
    "         query_size=QUERY_SIZE\n",
    "      )\n",
    "\n",
    "      # Inner Training Loop\n",
    "      for inner_iteration in range(self.inner_batch_size):\n",
    "\n",
    "        perm = torch.randperm(X_support.shape[0])\n",
    "\n",
    "        # Process Meta Learning Batches\n",
    "        for batch in range(0, X_support.shape[0], self.meta_batch_size):\n",
    "\n",
    "          # Get Permuted Batch from Sample\n",
    "          idx = perm[batch:batch + self.meta_batch_size]\n",
    "\n",
    "          # Calculate Batch Loss\n",
    "          self.model.zero_grad()\n",
    "          batch_loss = self.loss(X_support[idx], y_support[idx])\n",
    "          batch_loss.backward()\n",
    "\n",
    "          # Update Model Parameters\n",
    "          for theta in self.model.parameters():\n",
    "\n",
    "            if theta.grad is not None:\n",
    "                theta.data -= self.inner_step_size * theta.grad.data\n",
    "\n",
    "      # Compute meta-loss\n",
    "      with torch.no_grad():\n",
    "         query_loss = self.loss(X_query, y_query)\n",
    "\n",
    "      # Linear Cooling Schedule\n",
    "      alpha = self.outer_step_size * (1 - outer_iteration / self.outer_iterations)\n",
    "\n",
    "      # Get Current Candidate Weights\n",
    "      candidate_weights = self.model.state_dict()\n",
    "\n",
    "      # Transfer Candidate Weights to Model State Checkpoint\n",
    "      state_dict = {candidate: (current_weights[candidate] + alpha * \n",
    "                               (candidate_weights[candidate] - current_weights[candidate])) \n",
    "                                for candidate in candidate_weights}\n",
    "      self.model.load_state_dict(state_dict)\n",
    "      \n",
    "      # Log new Training Loss\n",
    "      self.log.add_scalar('ModelEstimate/Loss', query_loss.item(), outer_iteration)\n",
    "\n",
    "      # Log evaluation accuracy\n",
    "      if outer_iteration % 50 == 0:\n",
    "        mean_acc, _ = evaluate_episodes(self, X, y, allowed_classes=train_classes, n_episodes=50)\n",
    "        self.log.add_scalar('Episode/MeanAccuracy', mean_acc, outer_iteration)\n",
    "\n",
    "  def loss(self, x, y):\n",
    "\n",
    "    # Calculate Torch Tensors\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # Compute model output\n",
    "    logits = self.model(x)\n",
    "\n",
    "    # Cross Entropy Loss\n",
    "    calculatedLoss = nn.CrossEntropyLoss()\n",
    "    output = calculatedLoss(logits, y)\n",
    "\n",
    "    return output\n",
    "\n",
    "  def predict(self, x):\n",
    "\n",
    "    # Estimate using Torch Model\n",
    "    t = torch.tensor(x, device = device, dtype = torch.float32)\n",
    "    t = self.model(t)\n",
    "\n",
    "    prediction = torch.argmax(t, dim=1)\n",
    "\n",
    "    return prediction.cpu().numpy()\n",
    "\n",
    "  def eval(self, X, y, allowed_classes, gradient_steps=5):\n",
    "      self.model.eval()\n",
    "\n",
    "      # Sample a task\n",
    "      (X_support, y_support), (X_query, y_query) = sample_task(\n",
    "         X, y,\n",
    "         allowed_classes=allowed_classes,\n",
    "         n_way=N_WAY,\n",
    "         k_shot=K_SHOT,\n",
    "         query_size=QUERY_SIZE\n",
    "      )\n",
    "\n",
    "      # Store Meta-Initialization Weights\n",
    "      meta_weights = deepcopy(self.model.state_dict())\n",
    "\n",
    "      # Calculate Estimate over Gradient Steps\n",
    "      for step in range(gradient_steps):\n",
    "\n",
    "        # Calculate Evaluation Loss and Backpropagate\n",
    "        self.model.zero_grad()\n",
    "        loss = self.loss(X_support, y_support)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update Model Estimate Parameters\n",
    "        for theta in self.model.parameters():\n",
    "\n",
    "            if theta.grad is not None:\n",
    "                theta.data -= self.inner_step_size * theta.grad.data\n",
    "\n",
    "      # Get Estimate Loss over Evaluation\n",
    "      with torch.no_grad():\n",
    "          logits = self.model(X_query.to(device))\n",
    "          predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "      # Accuracy\n",
    "      accuracy = (predictions == y_query.to(device)).float().mean().item()\n",
    "\n",
    "      # Restore Meta-Initialization Weights\n",
    "      self.model.load_state_dict(meta_weights)\n",
    "      self.model.train()\n",
    "\n",
    "      return accuracy\n",
    "\n",
    "def evaluate_episodes(model, X, y, allowed_classes, n_episodes=100, gradient_steps=5):\n",
    "    accs = []\n",
    "    for _ in range(n_episodes):\n",
    "        acc = model.eval(X, y, allowed_classes=allowed_classes, gradient_steps=gradient_steps)\n",
    "        accs.append(acc)\n",
    "    return float(np.mean(accs)), float(np.std(accs))"
   ],
   "outputs": [],
   "execution_count": 207
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARn0cnaCT4I6"
   },
   "source": [
    "#### PyTorch Module"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fzQaKtGLT4YP",
    "ExecuteTime": {
     "end_time": "2025-11-18T19:27:20.883080Z",
     "start_time": "2025-11-18T19:27:20.877814Z"
    }
   },
   "source": [
    "N_WAY = 3       # number of classes per episode\n",
    "K_SHOT = 5      # support samples per class\n",
    "QUERY_SIZE = 15  # query samples per class\n",
    "HIDDEN_DIM = 128\n",
    "\n",
    "class TorchModule(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=HIDDEN_DIM, num_classes=N_WAY):\n",
    "        super(TorchModule, self).__init__()\n",
    "\n",
    "        self.input = nn.Linear(input_dim, hidden_dim)\n",
    "        self.hidden = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input(x))\n",
    "        x = torch.relu(self.hidden(x))\n",
    "        return self.output(x)\n"
   ],
   "outputs": [],
   "execution_count": 208
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cdfjr05yiF_T"
   },
   "source": [
    "### Learning Task"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Task Sampler"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T19:27:20.892812Z",
     "start_time": "2025-11-18T19:27:20.883080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sample_task(X, y, allowed_classes, n_way=N_WAY, k_shot=K_SHOT, query_size=QUERY_SIZE):\n",
    "    # Work with numpy view of labels\n",
    "    y_np = y.cpu().numpy()\n",
    "    needed = k_shot + query_size\n",
    "\n",
    "    # Only classes that are allowed AND have enough samples\n",
    "    valid_classes = [\n",
    "        c for c in allowed_classes\n",
    "        if np.sum(y_np == c) >= needed\n",
    "    ]\n",
    "\n",
    "    if len(valid_classes) < n_way:\n",
    "        raise ValueError(\"Not enough valid classes for this N-way task\")\n",
    "\n",
    "    # Randomly choose n_way classes from the valid ones\n",
    "    classes = np.random.choice(valid_classes, n_way, replace=False)\n",
    "\n",
    "    support_X = []\n",
    "    support_y = []\n",
    "    query_X = []\n",
    "    query_y = []\n",
    "\n",
    "    # Map global label -> episodic label 0..n_way-1\n",
    "    class_mapping = {int(c): i for i, c in enumerate(classes)}\n",
    "\n",
    "    for c in classes:\n",
    "        idx = np.where(y_np == c)[0]             # indices of this class\n",
    "        chosen = np.random.choice(idx, needed, replace=False)\n",
    "\n",
    "        support = chosen[:k_shot]\n",
    "        query = chosen[k_shot:]\n",
    "\n",
    "        # X is a torch tensor; numpy indices are fine\n",
    "        support_X.append(X[support])\n",
    "        query_X.append(X[query])\n",
    "\n",
    "        # Episodic labels 0..n_way-1 as torch.long\n",
    "        episodic_label = class_mapping[int(c)]\n",
    "        support_y.append(torch.full((len(support),), episodic_label, dtype=torch.long))\n",
    "        query_y.append(torch.full((len(query),), episodic_label, dtype=torch.long))\n",
    "\n",
    "    X_support = torch.cat(support_X, dim=0)\n",
    "    y_support = torch.cat(support_y, dim=0)\n",
    "    X_query = torch.cat(query_X, dim=0)\n",
    "    y_query = torch.cat(query_y, dim=0)\n",
    "\n",
    "    return (X_support, y_support), (X_query, y_query)\n"
   ],
   "outputs": [],
   "execution_count": 209
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Preprocessing"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T19:27:22.090561Z",
     "start_time": "2025-11-18T19:27:20.897996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"dataset/ML-EdgeIIoT-dataset-test.csv\", low_memory=False)\n",
    "\n",
    "# Encode Attack_type labels\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(df[\"Attack_type\"])\n",
    "\n",
    "# Separate features and binary attack label\n",
    "df = df.drop(columns=[\"Attack_label\", \"Attack_type\"])\n",
    "\n",
    "# Keep only numeric features\n",
    "df = df.select_dtypes(include=[\"number\"])\n",
    "X = df.values\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Convert to tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "print(\"Dataset loaded:\", X.shape, y.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: torch.Size([157800, 42]) torch.Size([157800])\n"
     ]
    }
   ],
   "execution_count": 210
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9W4j4rW0yuS"
   },
   "source": "#### Split Data"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T19:27:22.293608Z",
     "start_time": "2025-11-18T19:27:22.115714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get all unique class labels\n",
    "all_classes = np.unique(y.numpy())\n",
    "\n",
    "# Fix seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Choose 80% classes for meta-training\n",
    "num_meta_train = int(0.8 * len(all_classes))\n",
    "train_classes = np.random.choice(all_classes, size=num_meta_train, replace=False)\n",
    "\n",
    "# Remaining classes are test\n",
    "test_classes = np.array([c for c in all_classes if c not in train_classes])\n",
    "\n",
    "print(\"Train Classes:\", train_classes)\n",
    "print(\"Test Classes:\", test_classes)\n",
    "\n",
    "# Create dataset masks\n",
    "train_mask = np.isin(y.numpy(), train_classes)\n",
    "test_mask  = np.isin(y.numpy(), test_classes)\n",
    "\n",
    "# Filter datasets\n",
    "X_train = X[train_mask]\n",
    "y_train = y[train_mask]\n",
    "\n",
    "X_test  = X[test_mask]\n",
    "y_test  = y[test_mask]\n",
    "\n",
    "print(\"Train set:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set:\",  X_test.shape,  y_test.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Classes: [ 9 11  0 13  5  8  2  1 14  4  7 10]\n",
      "Test Classes: [ 3  6 12]\n",
      "Train set: torch.Size([136070, 42]) torch.Size([136070])\n",
      "Test set: torch.Size([21730, 42]) torch.Size([21730])\n"
     ]
    }
   ],
   "execution_count": 211
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Experiments"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RDm4ny3Qt0em",
    "ExecuteTime": {
     "end_time": "2025-11-18T19:30:34.125549Z",
     "start_time": "2025-11-18T19:27:22.302833Z"
    }
   },
   "source": [
    "# Define Experiment Parameters\n",
    "inner_step_size = 0.05\n",
    "inner_batch_size = 32\n",
    "\n",
    "outer_step_size = 0.1\n",
    "outer_iterations = 3000\n",
    "meta_batch_size = 32\n",
    "\n",
    "params = [inner_step_size, inner_batch_size,\n",
    "          outer_step_size, outer_iterations, meta_batch_size]\n",
    "\n",
    "# Build Model\n",
    "input_dim = X.shape[1]\n",
    "log = SummaryWriter(data_folder)\n",
    "reptile_model = Reptile(TorchModule(input_dim, hidden_dim=HIDDEN_DIM, num_classes=N_WAY), log, params)\n",
    "\n",
    "# Train Model\n",
    "reptile_model.train(X_train, y_train)\n",
    "\n",
    "log.close()\n",
    "\n",
    "# Zero-day evaluation on unseen test classes\n",
    "mean_acc, std_acc = evaluate_episodes(\n",
    "    reptile_model,\n",
    "    X_test, y_test,\n",
    "    allowed_classes=test_classes,\n",
    "    n_episodes=200\n",
    ")\n",
    "\n",
    "ci = 1.96 * std_acc / np.sqrt(200)\n",
    "print(f\"Zero-Day {N_WAY}-Way Accuracy: {mean_acc:.4f} ± {ci:.4f}\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eddf08498ecd4a6e9a5307fae9f961d8"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-Day 3-Way Accuracy: 0.8079 ± 0.0105\n"
     ]
    }
   ],
   "execution_count": 212
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jiPJ9EM9278"
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SixEsDGC0y7s",
    "ExecuteTime": {
     "end_time": "2025-11-18T19:30:34.205651Z",
     "start_time": "2025-11-18T19:30:34.186727Z"
    }
   },
   "source": [
    "%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir data"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 996), started 3:06:01 ago. (Use '!kill 996' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "74259bdd3e5071eb72e94b6045cbe810"
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-de0751ec4d7fb352\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-de0751ec4d7fb352\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 213
  }
 ]
}
