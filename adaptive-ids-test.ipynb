{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Torch Reptile Repository",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tda4Yz3rG2v7"
   },
   "source": [
    "# **Automated Machine Learning**\n",
    "\n",
    "---\n",
    "\n",
    "### **Torch Reptile - Parallel Metalearning**\n",
    "*Fall 2020 | Ruduan B.F. Plug*\n",
    "\n",
    "---\n",
    "\n",
    "<font size=\"1\">*Based on the Original Implementation by Alex Nichol & John Schulman [[1]](https://openai.com/blog/reptile/)*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzQ1T6HWX-S5"
   },
   "source": [
    "### Meta Libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YuqzrXatX_j1"
   },
   "source": [
    "# System Utility\n",
    "import sys\n",
    "\n",
    "# IPython Notebook Utilities\n",
    "from IPython.display import clear_output\n",
    "import tqdm.notebook as tqdm\n",
    "clear_output()\n",
    "\n",
    "print(sys.version)"
   ],
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHOC5HMhP3sA"
   },
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MZ0KiCd6P34h",
    "ExecuteTime": {
     "end_time": "2025-11-18T17:18:23.448102Z",
     "start_time": "2025-11-18T17:18:23.437424Z"
    }
   },
   "source": [
    "# Data Processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Model Library\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parallel Compute\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Utility Libraries\n",
    "import random\n",
    "import math\n",
    "from time import time\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Device\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Torch Version\\t\", torch.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version\t 2.9.0+cpu\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahVLMwR55Rsz"
   },
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WM48Nv385dcL",
    "ExecuteTime": {
     "end_time": "2025-11-18T17:18:23.463743Z",
     "start_time": "2025-11-18T17:18:23.453760Z"
    }
   },
   "source": [
    "data_folder = \"data\"\r\n",
    "np.random.seed(int(time()))\r\n",
    "torch.manual_seed(int(time()))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x29d3307c910>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 91
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFHo5IKxtA_L"
   },
   "source": "### Reptile TensorFlow"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xti4UH95t4TI"
   },
   "source": [
    "#### Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2TEFbIOEtIR2",
    "ExecuteTime": {
     "end_time": "2025-11-18T17:18:23.483381Z",
     "start_time": "2025-11-18T17:18:23.469055Z"
    }
   },
   "source": [
    "class Reptile:\n",
    "\n",
    "  def __init__(self, model, log, params):\n",
    "\n",
    "    # Intialize Reptile Parameters\n",
    "    self.inner_step_size = params[0]\n",
    "    self.inner_batch_size = params[1]\n",
    "    self.outer_step_size = params[2]\n",
    "    self.outer_iterations = params[3]\n",
    "    self.meta_batch_size = params[4] \n",
    "    self.eval_iterations = params[5] \n",
    "    self.eval_batch_size = params[6]\n",
    "\n",
    "    # Initialize Torch Model and Tensorboard\n",
    "    self.model = model.to(device)\n",
    "    self.log = log\n",
    "\n",
    "  def reset(self):\n",
    "\n",
    "    # Reset Training Gradients\n",
    "    self.model.zero_grad()\n",
    "\n",
    "  def train(self, X, y):\n",
    "\n",
    "    # Train from Scratch\n",
    "    self.reset()\n",
    "    self.model.train()\n",
    "\n",
    "    # Outer Training Loop\n",
    "    for outer_iteration in tqdm.tqdm(range(self.outer_iterations)):\n",
    "\n",
    "      # Track Current Weights\n",
    "      current_weights = deepcopy(self.model.state_dict())\n",
    "\n",
    "      # Sample a new Subtask\n",
    "      (X_support, y_support), (X_query, y_query) = sample_task(\n",
    "         X, y,\n",
    "         n_way=N_WAY,\n",
    "         k_shot=K_SHOT,\n",
    "         query_size=QUERY_SIZE\n",
    "      )\n",
    "\n",
    "      # Inner Training Loop\n",
    "      for inner_iteration in range(self.inner_batch_size):\n",
    "\n",
    "        perm = torch.randperm(X_support.shape[0])\n",
    "\n",
    "        # Process Meta Learning Batches\n",
    "        for batch in range(0, X_support.shape[0], self.meta_batch_size):\n",
    "\n",
    "          # Get Permuted Batch from Sample\n",
    "          idx = perm[batch:batch + self.meta_batch_size]\n",
    "\n",
    "          # Calculate Batch Loss\n",
    "          self.model.zero_grad()\n",
    "          batch_loss = self.loss(X_support[idx], y_support[idx])\n",
    "          batch_loss.backward()\n",
    "\n",
    "          # Update Model Parameters\n",
    "          for theta in self.model.parameters():\n",
    "\n",
    "            if theta.grad is not None:\n",
    "                theta.data -= self.inner_step_size * theta.grad.data\n",
    "\n",
    "      # Compute meta-loss\n",
    "      with torch.no_grad():\n",
    "         query_loss = self.loss(X_query, y_query)\n",
    "\n",
    "      # Linear Cooling Schedule\n",
    "      alpha = self.outer_step_size * (1 - outer_iteration / self.outer_iterations)\n",
    "\n",
    "      # Get Current Candidate Weights\n",
    "      candidate_weights = self.model.state_dict()\n",
    "\n",
    "      # Transfer Candidate Weights to Model State Checkpoint\n",
    "      state_dict = {candidate: (current_weights[candidate] + alpha * \n",
    "                               (candidate_weights[candidate] - current_weights[candidate])) \n",
    "                                for candidate in candidate_weights}\n",
    "      self.model.load_state_dict(state_dict)\n",
    "      \n",
    "      # Log new Training Loss\n",
    "      self.log.add_scalars('Model Estimate',\n",
    "                           {'Loss' : query_loss.item()},\n",
    "                           outer_iteration)\n",
    "\n",
    "      if outer_iteration % 50 == 0:\n",
    "        mean_acc, _ = evaluate_episodes(self, X, y, n_episodes=20)\n",
    "        self.log.add_scalar('Episode/MeanAccuracy', mean_acc, outer_iteration)\n",
    "\n",
    "  def loss(self, x, y):\n",
    "\n",
    "    # Calculate Torch Tensors\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # Compute model output\n",
    "    logits = self.model(x)\n",
    "\n",
    "    # Cross Entropy Loss\n",
    "    calculatedLoss = nn.CrossEntropyLoss()\n",
    "    output = calculatedLoss(logits, y)\n",
    "\n",
    "    return output\n",
    "\n",
    "  def predict(self, x):\n",
    "\n",
    "    # Estimate using Torch Model\n",
    "    t = torch.tensor(x, device = device, dtype = torch.float32)\n",
    "    t = self.model(t)\n",
    "\n",
    "    prediction = torch.argmax(t, dim=1)\n",
    "\n",
    "    return prediction.cpu().numpy()\n",
    "\n",
    "  def eval(self, X, y, support_size=32, gradient_steps=5):\n",
    "\n",
    "      # Sample a task\n",
    "      (X_support, y_support), (X_query, y_query) = sample_task(\n",
    "         X, y,\n",
    "         n_way=N_WAY,\n",
    "         k_shot=K_SHOT,\n",
    "         query_size=QUERY_SIZE\n",
    "      )\n",
    "\n",
    "      # Store Meta-Initialization Weights\n",
    "      meta_weights = deepcopy(self.model.state_dict())\n",
    "\n",
    "      # Calculate Estimate over Gradient Steps\n",
    "      for step in range(gradient_steps):\n",
    "\n",
    "        # Calculate Evaluation Loss and Backpropagate\n",
    "        self.model.zero_grad()\n",
    "        loss = self.loss(X_support, y_support)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update Model Estimate Parameters\n",
    "        for theta in self.model.parameters():\n",
    "\n",
    "            if theta.grad is not None:\n",
    "                theta.data -= self.inner_step_size * theta.grad.data\n",
    "\n",
    "      # Get Estimate Loss over Evaluation\n",
    "      with torch.no_grad():\n",
    "          logits = self.model(X_query.to(device))\n",
    "          predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "      # Accuracy\n",
    "      accuracy = (predictions == y_query.to(device)).float().mean().item()\n",
    "\n",
    "      # Restore Meta-Initialization Weights\n",
    "      self.model.load_state_dict(meta_weights)\n",
    "\n",
    "      return accuracy\n",
    "\n",
    "def evaluate_episodes(model, X, y, n_episodes=100, gradient_steps=5):\n",
    "    accs = []\n",
    "    for _ in range(n_episodes):\n",
    "        acc = model.eval(X, y, gradient_steps=gradient_steps)\n",
    "        accs.append(acc)\n",
    "    return float(np.mean(accs)), float(np.std(accs))"
   ],
   "outputs": [],
   "execution_count": 92
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARn0cnaCT4I6"
   },
   "source": [
    "#### PyTorch Module"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fzQaKtGLT4YP",
    "ExecuteTime": {
     "end_time": "2025-11-18T17:18:23.492292Z",
     "start_time": "2025-11-18T17:18:23.487409Z"
    }
   },
   "source": [
    "N_WAY = 5       # number of classes per episode\n",
    "K_SHOT = 5      # support samples per class\n",
    "QUERY_SIZE = 15 # query samples per class\n",
    "HIDDEN_DIM = 128\n",
    "\n",
    "class TorchModule(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=HIDDEN_DIM, num_classes=N_WAY):\n",
    "        super(TorchModule, self).__init__()\n",
    "\n",
    "        self.input = nn.Linear(input_dim, hidden_dim)\n",
    "        self.hidden = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input(x))\n",
    "        x = torch.relu(self.hidden(x))\n",
    "        return self.output(x)\n"
   ],
   "outputs": [],
   "execution_count": 93
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cdfjr05yiF_T"
   },
   "source": [
    "### Learning Task"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Task Sampler"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T17:18:23.502885Z",
     "start_time": "2025-11-18T17:18:23.492292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sample_task(X, y, n_way=N_WAY, k_shot=K_SHOT, query_size=QUERY_SIZE):\n",
    "    # Work with numpy view of labels\n",
    "    y_np = y.cpu().numpy()\n",
    "\n",
    "    # How many samples do we need per class in this episode?\n",
    "    needed = k_shot + query_size\n",
    "\n",
    "    # Only keep classes that have enough examples\n",
    "    (unique_classes, counts) = np.unique(y_np, return_counts=True)\n",
    "    valid_classes = unique_classes[counts >= needed]\n",
    "\n",
    "    if len(valid_classes) < n_way:\n",
    "        raise ValueError(\n",
    "            f\"Not enough classes with at least {needed} samples: \"\n",
    "            f\"found {len(valid_classes)}, need {n_way}\"\n",
    "        )\n",
    "\n",
    "    # Randomly choose n_way classes from the valid ones\n",
    "    classes = np.random.choice(valid_classes, n_way, replace=False)\n",
    "\n",
    "    support_X = []\n",
    "    support_y = []\n",
    "    query_X = []\n",
    "    query_y = []\n",
    "\n",
    "    # Map global label -> episodic label 0..n_way-1\n",
    "    class_mapping = {int(c): i for i, c in enumerate(classes)}\n",
    "\n",
    "    for c in classes:\n",
    "        idx = np.where(y_np == c)[0]             # indices of this class\n",
    "        chosen = np.random.choice(idx, needed, replace=False)\n",
    "\n",
    "        support = chosen[:k_shot]\n",
    "        query = chosen[k_shot:]\n",
    "\n",
    "        # X is a torch tensor; numpy indices are fine\n",
    "        support_X.append(X[support])\n",
    "        query_X.append(X[query])\n",
    "\n",
    "        # Episodic labels 0..n_way-1 as torch.long\n",
    "        episodic_label = class_mapping[int(c)]\n",
    "        support_y.append(torch.full((len(support),), episodic_label, dtype=torch.long))\n",
    "        query_y.append(torch.full((len(query),), episodic_label, dtype=torch.long))\n",
    "\n",
    "    X_support = torch.cat(support_X, dim=0)\n",
    "    y_support = torch.cat(support_y, dim=0)\n",
    "    X_query = torch.cat(query_X, dim=0)\n",
    "    y_query = torch.cat(query_y, dim=0)\n",
    "\n",
    "    return (X_support, y_support), (X_query, y_query)\n"
   ],
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Dataset"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T17:18:24.871495Z",
     "start_time": "2025-11-18T17:18:23.507810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"dataset/ML-EdgeIIoT-dataset-test.csv\", low_memory=False)\n",
    "\n",
    "# Encode Attack_type labels\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(df[\"Attack_type\"])\n",
    "\n",
    "# Separate features and binary attack label\n",
    "df = df.drop(columns=[\"Attack_label\", \"Attack_type\"])\n",
    "\n",
    "# Keep only numeric features\n",
    "df = df.select_dtypes(include=[\"number\"])\n",
    "X = df.values\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Convert to tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "print(\"Dataset loaded:\", X.shape, y.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: torch.Size([157800, 42]) torch.Size([157800])\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9W4j4rW0yuS"
   },
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RDm4ny3Qt0em",
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-18T17:18:24.989327Z"
    }
   },
   "source": [
    "# Define Experiment Parameters\n",
    "inner_step_size = 0.02\n",
    "inner_batch_size = 32\n",
    "\n",
    "outer_step_size = 0.05\n",
    "outer_iterations = 3000\n",
    "meta_batch_size = 32\n",
    "\n",
    "eval_iterations = 32\n",
    "eval_batch_size = 10\n",
    "\n",
    "params = [inner_step_size, inner_batch_size,\n",
    "          outer_step_size, outer_iterations, meta_batch_size,\n",
    "          eval_iterations, eval_batch_size]\n",
    "\n",
    "# Build Model\n",
    "input_dim = X.shape[1]\n",
    "log = SummaryWriter(data_folder)\n",
    "reptile_model = Reptile(TorchModule(input_dim, hidden_dim=HIDDEN_DIM, num_classes=N_WAY), log, params)\n",
    "\n",
    "# Train Model\n",
    "reptile_model.train(X, y)\n",
    "\n",
    "log.close()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9546121006764773936a5268264d13f4"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jiPJ9EM9278"
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SixEsDGC0y7s",
    "ExecuteTime": {
     "end_time": "2025-11-18T17:18:01.012219Z",
     "start_time": "2025-11-18T17:18:00.994980Z"
    }
   },
   "source": [
    "%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir data"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 996), started 0:53:28 ago. (Use '!kill 996' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "00968ab9b2539a444ed4f94bd1470c23"
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1b23f4aab287c0dd\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1b23f4aab287c0dd\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 88
  }
 ]
}
